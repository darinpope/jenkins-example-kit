{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807cc10e-f58f-4514-8010-e00e70794a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9ca70a-b9ec-4615-b5b6-385e8273d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76359ea5-997c-4150-9e7a-153fe7458907",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e4edd2-e076-4788-940d-902861eda5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "id                                     0\n",
       "Gender                                 0\n",
       "Customer Type                          0\n",
       "Age                                    0\n",
       "Type of Travel                         0\n",
       "Class                                  0\n",
       "Flight Distance                        0\n",
       "Inflight wifi service                  0\n",
       "Departure/Arrival time convenient      0\n",
       "Ease of Online booking                 0\n",
       "Gate location                          0\n",
       "Food and drink                         0\n",
       "Online boarding                        0\n",
       "Seat comfort                           0\n",
       "Inflight entertainment                 0\n",
       "On-board service                       0\n",
       "Leg room service                       0\n",
       "Baggage handling                       0\n",
       "Checkin service                        0\n",
       "Inflight service                       0\n",
       "Cleanliness                            0\n",
       "Departure Delay in Minutes             0\n",
       "Arrival Delay in Minutes             310\n",
       "satisfaction                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for Blank Values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40358bf8-37eb-499d-92bb-8c879cf679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Blank Values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e8c168-c783-46ae-9779-615af41fad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which just show the serial number\n",
    "data.drop(columns=['Unnamed: 0','id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd34a8a9-72c4-45f6-a476-ca54d6a7e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['satisfaction_labels'] = data['satisfaction'].apply(lambda x : 1 if x=='satisfied' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c51bf6-f609-437b-9d8e-da6d8411bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c4d3b9-13f0-4c13-8590-6e5b951bd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['satisfaction'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14123db8-9f3b-4a2a-acbc-e331ead2ad72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dde906d-504e-436b-9910-ee5b0e0299b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82875 train examples\n",
      "20719 validation examples\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(data, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6a1b4-5189-495f-b6ae-bc881b70aa79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Conversion to TF Dataset Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b71a873-bb44-4cd1-a6bc-5426faaaae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('satisfaction_labels')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c048a322-95ba-43b5-b714-e5a9359588f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0aef9d-e886-4994-8128-0327674e3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Gender', 'Customer_Type', 'Age', 'Type_of_Travel', 'Class', 'Flight_Distance', 'Inflight_wifi_service', 'Departure/Arrival_time_convenient', 'Ease_of_Online_booking', 'Gate_location', 'Food_and_drink', 'Online_boarding', 'Seat_comfort', 'Inflight_entertainment', 'On-board_service', 'Leg_room_service', 'Baggage_handling', 'Checkin_service', 'Inflight_service', 'Cleanliness', 'Departure_Delay_in_Minutes', 'Arrival_Delay_in_Minutes']\n",
      "A batch of ages: tf.Tensor(\n",
      "[11 26 44 49 44 20 37 32 34 55 43 77 57 19 18 35 38 36 58 49 46 42 54 25\n",
      " 42 54 66 45 46 41 26 42], shape=(32,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['Age'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b154f16-b668-48cd-8f48-e9c50fb65155",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819c6e85-895d-4c8e-8f1c-f427a0771b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['Age', 'Flight_Distance', 'Inflight_wifi_service', 'Departure/Arrival_time_convenient', 'Ease_of_Online_booking', 'Gate_location', 'Food_and_drink', 'Online_boarding', 'Seat_comfort', 'Inflight_entertainment', 'On-board_service', 'Leg_room_service', 'Baggage_handling', 'Checkin_service', 'Inflight_service', 'Cleanliness', 'Departure_Delay_in_Minutes', 'Arrival_Delay_in_Minutes']\n",
      "Categorical columns: ['Gender', 'Customer_Type', 'Type_of_Travel', 'Class']\n"
     ]
    }
   ],
   "source": [
    "element_spec = train_ds.element_spec\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = []\n",
    "categorical_cols = []\n",
    "for key, value in element_spec[0].items():\n",
    "    if value.dtype in (tf.float32, tf.float64, tf.int32, tf.int64):\n",
    "        numerical_cols.append(key)\n",
    "    else:\n",
    "        categorical_cols.append(key)\n",
    "\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7717323-2eb4-4fd0-a5d2-96568e98e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/17/55vyd88d1gx84jgr3vnt21t40000gn/T/ipykernel_36012/833704315.py:5: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for num_cols in numerical_cols:\n",
    "  feature_columns.append(feature_column.numeric_column(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8771f3ae-701a-41c4-a1c3-7953675ad84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/17/55vyd88d1gx84jgr3vnt21t40000gn/T/ipykernel_36012/572607349.py:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From /var/folders/17/55vyd88d1gx84jgr3vnt21t40000gn/T/ipykernel_36012/572607349.py:4: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "for col_name in categorical_cols:\n",
    "  categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "      col_name, data[col_name].unique())\n",
    "  indicator_column = feature_column.indicator_column(categorical_column)\n",
    "  feature_columns.append(indicator_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ad913-bc65-4880-91f0-5cbaf6986617",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d75fbed4-a436-4d31-8800-8889180f813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173b5f77-cf08-4839-89ce-c18246fe731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorkem/miniconda3/envs/mlflow-env/lib/python3.11/site-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2590/2590 [==============================] - 3s 807us/step - loss: 1.1729 - accuracy: 0.7050 - val_loss: 0.4058 - val_accuracy: 0.8496\n",
      "Epoch 2/10\n",
      "2590/2590 [==============================] - 2s 767us/step - loss: 0.4410 - accuracy: 0.8111 - val_loss: 0.3537 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "2590/2590 [==============================] - 2s 762us/step - loss: 0.3869 - accuracy: 0.8407 - val_loss: 0.3874 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "2590/2590 [==============================] - 2s 763us/step - loss: 0.3574 - accuracy: 0.8567 - val_loss: 0.3757 - val_accuracy: 0.8478\n",
      "Epoch 5/10\n",
      "2590/2590 [==============================] - 2s 772us/step - loss: 0.3292 - accuracy: 0.8681 - val_loss: 0.2768 - val_accuracy: 0.8877\n",
      "Epoch 6/10\n",
      "2590/2590 [==============================] - 2s 752us/step - loss: 0.2862 - accuracy: 0.8841 - val_loss: 0.2431 - val_accuracy: 0.8974\n",
      "Epoch 7/10\n",
      "2590/2590 [==============================] - 2s 757us/step - loss: 0.2479 - accuracy: 0.8977 - val_loss: 0.2385 - val_accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "2590/2590 [==============================] - 2s 754us/step - loss: 0.2223 - accuracy: 0.9081 - val_loss: 0.2000 - val_accuracy: 0.9137\n",
      "Epoch 9/10\n",
      "2590/2590 [==============================] - 2s 759us/step - loss: 0.2122 - accuracy: 0.9124 - val_loss: 0.1914 - val_accuracy: 0.9155\n",
      "Epoch 10/10\n",
      "2590/2590 [==============================] - 2s 776us/step - loss: 0.2084 - accuracy: 0.9135 - val_loss: 0.1782 - val_accuracy: 0.9269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x31f4db850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40c2da-76bb-4f27-b125-d71518217294",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df1725d6-4dad-4545-9e57-a0109cb90b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/812 [==============================] - 0s 414us/step\n",
      "Binary Predictions:\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Reading Test Data\n",
    "test_data = pd.read_csv(r'../data/test.csv')\n",
    "\n",
    "test_data.drop(columns=['Unnamed: 0','id'], inplace=True)\n",
    "test_data.columns = test_data.columns.str.replace(' ', '_')\n",
    "\n",
    "test_data['satisfaction_bin_labels'] = test_data['satisfaction'].apply(lambda x : 1 if x=='satisfied' else 0)\n",
    "\n",
    "test_features = {col: test_data[col].values for col in test_data.columns if col != 'satisfaction'}\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "# Assuming predictions are probabilities, convert them to binary labels (0 or 1)\n",
    "binary_predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Print or use binary_predictions as needed\n",
    "print(\"Binary Predictions:\")\n",
    "print(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "292c945d-20ca-4dfb-b97a-94e41dbf50ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     14573\n",
      "           1       0.93      0.90      0.91     11403\n",
      "\n",
      "    accuracy                           0.92     25976\n",
      "   macro avg       0.92      0.92      0.92     25976\n",
      "weighted avg       0.92      0.92      0.92     25976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model on Test Data\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_data['satisfaction_bin_labels'].values, binary_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e00fb-83ea-4205-9b73-1d66d704ec78",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c6af2b1-f324-4c48-a5df-9c3272ca9d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dl_model_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/dl_model_v1/assets\n"
     ]
    }
   ],
   "source": [
    "model_filename = \"dl_model_v1\"\n",
    "\n",
    "# Save the entire model (including architecture, optimizer, and learned weights)\n",
    "model.save(f\"../models/{model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103daacb-0006-4c1a-9844-438ed35530b9",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf353ba-e174-4bd6-a41c-9564d791fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a sample code for finetuning the model , you can customise it according to your implementation.\n",
    "# We have provided some default parameters & layers which you can customize.\n",
    "\n",
    "# def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    \n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.kayers.InputLayer(input_shape=input_shape))\n",
    "#     for layer in range(n_hidden):\n",
    "#         model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "#     model.add(tf.keras.layers.Dense(1))\n",
    "#     optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# tune_model_obj = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "# tune_model_obj.fit(X_train, y_train, epochs=10,\n",
    "#                     validation_data=(X_valid, y_valid),\n",
    "#                     callbacks=tf.keras.callbacks.EarlyStopping(patience=10))\n",
    "\n",
    "# param_space = {...}\n",
    "\n",
    "# rndm_search = RandomizedSearchCV(tune_model_obj, param_space, n_iter=10, cv=3)\n",
    "\n",
    "# rndm_search.fit(X_train, y_train, epochs=10,\n",
    "#                 validation_data=(X_valid, y_valid),\n",
    "#                 callbacks=tf.keras.callbacks.EarlyStopping(patience=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
